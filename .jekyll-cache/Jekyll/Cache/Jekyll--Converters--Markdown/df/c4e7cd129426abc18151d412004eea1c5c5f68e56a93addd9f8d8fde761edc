I"pœ<h2 id="2018-talks">2018 Talks</h2>

<h3 id="november-5th-comportamiento-rob√≥tico-de-seguimiento-de-personas-usando-deep-learning-nacho-cond√©s-uc3m">(November 5th) Comportamiento rob√≥tico de seguimiento de personas usando Deep Learning, Nacho Cond√©s (UC3M)</h3>

<p>Speaker: <a href="https://jderobot.org/Naxvm-tfg">Nacho Cond√©s</a> (U. Carlos III de Madrid, former student at URJC)</p>

<p>Abstract: En los √∫ltimos tiempos, la ciencia y la tecnolog√≠a est√°n experimentando un notorio auge en los campos como la rob√≥tica y las redes neuronales, que est√°n tomando un papel significativo. Si buscamos posibles sinergias entre ellas la percepci√≥n visual en rob√≥tica es un √°rea id√≥nea. En este contexto se sit√∫a el trabajo que se presenta en esta charla: hemos combinado una inteligencia visual programada mediante redes neuronales con aprendizaje profundo y unos algoritmos de control de movimientos en un robot m√≥vil equipado con un sensor econ√≥mico (RGBD, tipo Kinect) para que el robot sea capaz de seguir a una persona concreta, incluso aunque le de la espalda.</p>

<p>When?: 2018-11-05, 16:30h</p>

<p>Where?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>It is open to general public, but registration is required at this <a href="https://docs.google.com/forms/d/e/1FAIpQLSfSZ9SXzCxONk9PLnYWibv1tzBBwWpUBF259BqdhKs-BA4lYA/viewform">web page</a></p>

<p>Slides: <a href="http://jderobot.org/store/jmplaza/uploads/charlas/nacho_condes-follow_mom.pdf">slides</a></p>

<p><img src="/assets/images/activities/talks/charlaNachocondes2018.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="october-22nd-arduino-programming-in-python-sergio-paniego-upm">(October 22nd) Arduino Programming in Python, Sergio Paniego (UPM)</h3>

<p>Speaker: <a href="https://jderobot.org/Club-spaniego">Sergio Paniego</a> (U.Polit√©cnica de Madrid, former student at URJC)</p>

<p>Abstract PyOnArduino PyOnArduino is a tool developed by JdeRobot that enables Python programming of robots with an Arduino processor built-in. The developed approach uses a Python parser and automatically translates it to Arduino language (C / C ++ function set), which once compiled, can be downloaded and run on the Arduino processor. All this process is done with a single command. PyOnArduino‚Äôs development started this summer as part of Google Summer of Code, a program in which we took part. On this talk, the project will be displayed with a practical approach in mind, showing examples with real-world robots, and also presenting the experience of working on a GSoC project as a student.</p>

<p>When?: 2018-10-22, 16h</p>

<p>Where?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>It is open to general public, but registration is required at this <a href="https://docs.google.com/forms/d/e/1FAIpQLSe0JGtllGg4o4ThxPF5lSHksKeX7Ru522OQBvRpFjFJ5zKY-w/viewform">web page</a></p>

<p>Slides: <a href="https://jderobot.github.io/PyOnArduino/ArduinoProgrammingInPython.pdf">PyOnArduino slides</a></p>

<p><img src="/assets/images/activities/talks/charlaSergiopaniego2018.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="october-1st-spatial-task-allocation-in-search-and-rescue-okan-asik-boƒüazi√ßi-university">(October 1st) Spatial Task Allocation in Search and Rescue, Okan Asik (Boƒüazi√ßi University)</h3>

<p>Speaker: <a href="https://okanasik.github.io/">Okan Asik</a> (Boƒüazi√ßi University)</p>

<p>Abstract Search and rescue strategies are developed by human experts using the knowledge gathered from previous disasters. However, these procedures are not formally validated and does not follow scientific approach. We develop a decision-theoretic multi-agent planning approach for search and rescue tasks. Although, multi-agent decision-theoretic approaches fails to scale, we use the spatial property of tasks to reduce the complexity of the problem. We validate our approach using the RoboCup Rescue Agent Simulator.</p>

<p>When?: 2018-10-01, 16:30h</p>

<p>Where?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSev6Ros6qhiQYn8VmhICSPgnoQGy2BXtHHfwFYeC5suiQ2v1w/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/OAsik_rescuesim.pdf">trasparencias</a> que se usaron y el <a href="http://jderobot.org/store/jmplaza/uploads/charlas/urjc-okan-talk-2018.mp3">audio</a> grabado de la charla.</p>

<p><img src="/assets/images/activities/talks/charlaOkan2018.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="october-1st-jderobot-visualstates-tool-okan-asik-boƒüazi√ßi-university">(October 1st) JdeRobot VisualStates tool, Okan Asik (Boƒüazi√ßi University)</h3>

<p>Speaker: <a href="https://okanasik.github.io/">Okan Asik</a> (Boƒüazi√ßi University)</p>

<p>Abstract: The behavior programming is one of the fundamental tasks in robot programming. Its nature is different than other essential robotics modules such as perception and localization. Other robotics modules can be programmed and tackled in the level of algorithms, but robot behavior can also be represented by states. For example, simple wall following behavior can consist of two states; very close to the wall, very far away from the wall. The programmer can easily define specific commands for each state. JdeRobot VisualStates tool provides a visual programming environment for defining such reactive behaviors. It is developed as a ROS package and provides a mechanism to compose new behaviors by importing previously built behaviors. We plan to built a behavior repository where people can share different behaviors with each other and reuse already developed behaviors by adjusting the parameters of the behavior for their own use case.</p>

<p>When?: 2018-10-01, 16:30h</p>

<p>Where?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSev6Ros6qhiQYn8VmhICSPgnoQGy2BXtHHfwFYeC5suiQ2v1w/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/OAsik_VisualStates.pdf">trasparencias</a> que se usaron y el <a href="http://jderobot.org/store/jmplaza/uploads/charlas/urjc-okan-talk-2018.mp3">audio</a> grabado de la charla (desde minuto 30).</p>

<p><br /></p>

<h3 id="april-23rd-openvidu-una-plataforma-para-a√±adir-videoconferencia-en-grupo-en-tu-p√°gina-web-micael-gallego-urjc">(April 23rd) OpenVidu, una plataforma para a√±adir videoconferencia en grupo en tu p√°gina web, Micael Gallego (URJC)</h3>

<p>Speaker: Micael Gallego, profesor ETSII-URJC</p>

<p>Summary: La tecnolog√≠a WebRTC permite crear videollamadas entre dos browsers. Pero para las llamadas en grupo, es necesario un servidor de media. Con OpenVidu, crear una aplicaci√≥n de videollamadas en grupo es muy sencillo, s√≥lo tienes que usar una librer√≠a JS en el browser y el servidor de OpenVidu dockerizado. Y si quieres, puedes grabar la videollamada en disco. En esta sesi√≥n podr√°s ver lo f√°cil que es implementar este tipo de aplicaciones, y usando √∫nicamente tecnolog√≠as open source.</p>

<p>When?: 2018-04-23, 16:30h</p>

<p>Where?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSfEZQWFo79goOFkpVq9_fJWhPBD-wYcBcjYFqC9UosZz5m5MQ/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/traspas-mica-openvidu.pdf">trasparencias</a> que se usaron y el <a href="http://jderobot.org/store/jmplaza/uploads/charlas/audio-20180423.3gp">audio</a> grabado de la charla.</p>

<p><br /></p>

<h3 id="march-20th-dense-visual-slam-geometry--learning-javier-civera-uzaragoza">(March 20th) Dense Visual SLAM: Geometry + Learning, Javier Civera (U.Zaragoza)</h3>

<p>Ponente: Javier Civera, Doctor de la U.Zaragoza</p>

<p>Resumen: El objetivo del SLAM (acr√≥nimo de Simultaneous Localization and Mapping) visual es la estimaci√≥n de un mapa global de una escena y la autolocalizaci√≥n a partir de datos visuales. Actualmente es una disciplina de gran relevancia, debido a su madurez y a ser pieza clave de tecnolog√≠as emergentes como rob√≥tica m√≥vil, AR y VR. En esta charla se introducir√°n algunos algoritmos del estado del arte, con foco en 1) reconstrucciones 3D densas, 2) el potencial del aprendizaje autom√°tico (en concreto, deep learning) en SLAM, y 3) la fusi√≥n con otros sensores (principalmente inerciales).</p>

<p>¬øCu√°ndo?: 2018-03-20, 18h</p>

<p>¬øD√≥nde?: Sal√≥n de Grados, edificio departamental II, campus de M√≥stoles de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSevCrhKu_d4GxMaXMeCy6hdnDMmF2tOSf7sdr8VLwa7JvUsOQ/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/civera-traspas2018.pdf">trasparencias</a> que se usaron y el <a href="http://jderobot.org/store/jmplaza/uploads/charlas/slam-civera-2018.mp3">audio</a> grabado de la charla.</p>

<p><img src="/assets/images/activities/talks/charlaCivera2018.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="february-13th-aplicaci√≥n-de-t√©cnicas-de-deep-learning-a-reconocimiento-de-objetos-en-visi√≥n-miguel-cazorla-ualicante">(February 13th) Aplicaci√≥n de t√©cnicas de deep learning a reconocimiento de objetos en visi√≥n, Miguel Cazorla (U.Alicante)</h3>

<p>Ponente: Miguel Cazorla Quevedo, catedr√°tico de la U.Alicante</p>

<p>Resumen: hablaremos de varios trabajos sobre reconocimiento de objetos usando t√©cnicas de deep learning. En el primero, se explicar√° c√≥mo se puede obtener el modelo 3D de una mano a partir de im√°genes 2D. Se comentar√° el dataset realizado para obtener manos con sus datos 3D anotados. A continuaci√≥n, veremos el pipeline de la aplicaci√≥n completo, desde la aplicaci√≥n de una RCNN para detectar la mano hasta la regresi√≥n realizada para obtener las coordenadas de los distintos dedos. En el segundo se explicar√° c√≥mo se puede abordar el reconocimiento de insectos. Este problema es de clasificaci√≥n, pero tiene ciertos dificultades a la hora de organizar la informaci√≥n. Se detallar√°n los pasos que hemos seguido y los resultados obtenidos. Por √∫ltimo se comentar√° una manera de obtener la informaci√≥n 3D de una escena a partir √∫nicamente de una imagen 2D. Este trabajo est√° en desarrollo, pero se comentar√° la manera de abordarlo.</p>

<p>¬øCu√°ndo?: 2018-02-13, 18h</p>

<p>¬øD√≥nde?: Aula 170, edificio departamental II, campus de M√≥stoles de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSdOMEf97M0DKwoLtid57R12cT86cN3rApl263Zgl0YmnfOXmQ/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/cazorla-traspas2018.pdf">trasparencias</a>.</p>

<p><img src="/assets/images/activities/talks/charlaMiguel2018.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h2 id="2017-talks">2017 Talks</h2>

<h3 id="noviembre-28-aplicaci√≥n-pr√°ctica-de-la-rob√≥tica-en-procesos-empresariales-y-financieros-luis-gonz√°lez-gugel-deloitte">(noviembre 28) Aplicaci√≥n pr√°ctica de la Rob√≥tica en procesos empresariales y financieros, Luis Gonz√°lez Gugel (Deloitte)</h3>

<p>Ponente: Luis Gonzalez Gugel, Socio de Deloitte responsable del √°rea de Robotics</p>

<p>Resumen: La inevitable realidad en el mundo de los negocios es la continua b√∫squeda por adquirir una ventaja competitiva. La empresa que es capaz de proporcionar las soluciones m√°s eficientes a las necesidades de sus clientes, es la que se encontrar√° capturando el mercado. La b√∫squeda de eficiencia se ha convertido en una carrera por transferir actividades transaccionales a m√°quinas que pueden realizarlas de manera r√°pida y con un m√≠nimo de errores, liberando el tiempo de las personas para que se puedan enfocar en actividades de √≠ndole estrat√©gica; aprovechando la creatividad humana para mejorar los negocios, en vez de ocuparlos en actividades repetitivas.</p>

<p>La nueva era digital trae consigo un futuro en el cual las m√°quinas empiezan a aprender de los seres humanos; y a medida que estas se vuelvan mejor en su labor, su demanda y permeabilidad en el d√≠a a d√≠a de las empresas ser√° m√°s prevalente. Aunque esta tecnolog√≠a a√∫n se encuentra en una etapa de desarrollo, ya ha rendido sus primeros frutos mediante la Automatizaci√≥n Rob√≥tica de Procesos (RPA). Los robots en este caso no son f√≠sicos, sino una evoluci√≥n del software, pero su objetivo es contundente con el resto de la ideolog√≠a de esta revoluci√≥n; permitiendo la automatizaci√≥n de porciones de procesos que no requieran del juicio humano.</p>

<p>Para el 2020, RPA ser√° una herramienta com√∫n y se espera que para el 2025 sea com√∫n encontrar maquinas inteligentes con capacidad de aprendizaje en gran parte de los negocios, sobrepasando la limitante transaccional de los sistemas actuales. Se espera que para el 2025 la inteligencia artificial sea parte de los negocios, esta permitir√° reconocimiento y procesamiento del lenguaje natural, capacidad para trabajar con grandes vol√∫menes de datos no estructurados, an√°lisis predictivo basado en un hip√≥tesis, capacidades avanzadas de aprendizaje y mejora de rendimiento.</p>

<p>¬øCu√°ndo?: 2017-11-28, 15:30h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSfdOZhr8jLUNS7bbsz4AbC7pdXVAZI5MWqEpTX8WIdf9nbTQQ/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/20171128-urjc-deloitte.pdf">trasparencias</a> que se usaron.</p>

<p><img src="/assets/images/activities/talks/charlaDeloitte.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="noviembre-20-electr√≥nica-digital-para-todos-con-fpgas-libres-juan-gonz√°lez">(noviembre 20) Electr√≥nica digital para todos con FPGAs libres, Juan Gonz√°lez</h3>

<p>Ponente: Juan Gonz√°lez (ObiJuan)</p>

<p>Resumen: La electr√≥nica digital es la base con la que se dise√±an todos los chips digitales que est√°n en nuestros m√≥viles, ordenadores, tablets, televisores‚Ä¶ ¬øSer√≠a posible acercar esta tecnolog√≠a a personas no t√©cnicas, y que pudiesen crear sus propios circuios digitales? Con las FPGAs libres esto es viable, y podemos sintetizar circuitos sencillos en segundos, siguiendo un ciclo de dise√±o tan r√°pido como el del software. La charla ser√° fundamentalmente pr√°ctica, donde se har√°n demostraciones</p>

<p>¬øCu√°ndo?: 2017-11-20, 15:30h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSeFEZHKYik7fEwzqfYCCOwb988UJxHHa-dCZE-Y7XAtCwrUag/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/2017-11-20-URJC-FPGAs-libres.pdf">trasparencias</a> que se usaron.</p>

<p><img src="/assets/images/activities/talks/charlaElectronicaJuan.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="marzo-28-enriqueciendo-aplicaciones-webrtc-con-kurento-miguel-par√≠s">(marzo 28) Enriqueciendo aplicaciones WebRTC con Kurento, Miguel Par√≠s</h3>

<p>Ponente: Miguel Par√≠s (Twilio)</p>

<p>Resumen: En el marco de las aplicaciones multimedia distribuidas se expondr√°n los fundamentos y la filosof√≠a de Kurento, las abstracciones que ofrece para facilitar el desarrollo de aplicaciones comunicaciones/multimedia, entre los que hablaremos de qu√© elemento implementa los est√°ndares de WebRTC y de esta forma hacer una breve incursi√≥n en lo que es WebRTC y qu√© aporta al estado del arte actual. La idea es intercalar las explicaciones con peque√±as demos mostrando c√≥digo para ver f√°cilmente como encajan las ideas en la pr√°ctica.</p>

<p>¬øCu√°ndo?: 2017-03-28, 17h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSfG9dj18RaNi1OFGptNOE3ySy_5dkV_BG5Qr-Fy7RlfVeUHDg/closedform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/urjc-march-2017-mparis-003-simpler.pdf">trasparencias</a> que se usaron.</p>

<p>La puedes disfrutar en el canal de YouTube de JdeRobot:</p>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/K6K9KCuODUo" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><br /></p>

<p><br /></p>

<h3 id="marzo-24-retransmisi√≥n-en-directo-desde-un-drone-usando-youtube-alberto-pavo">(marzo 24) Retransmisi√≥n en directo desde un drone usando YouTube, Alberto Pavo</h3>

<p>Ponente: Alberto Pavo (GFT Spain)</p>

<p>Resumen: Se introducir√°n las tecnolog√≠as audiovisuales, el manejo de eventos en YouTube y las librer√≠as que proporciona Google (YouTube Data API) para el desarrollo de aplicaciones que gestionen contenido en YouTube, en concreto, eventos en directo. Tambi√©n se explicar√°n dos tipos de codificadores capaces de comunicarse con YouTube y enviar a sus servidores el contenido multimedia. Mezclando todo lo anterior se mostrar√° c√≥mo se usan esas tecnolog√≠as para retransmitir el contenido captado por un drone en tiempo real.</p>

<p>¬øCu√°ndo?: 2017-03-24, 16h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSdVDjOWCr5Eam3Az7iIM4geY_I0OS1XUwuDSCGNzk9rwYj81A/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/traspas-youtube-2017.pdf">trasparencias</a> que se usaron.</p>

<p>La puedes disfrutar en el canal de YouTube de JdeRobot:</p>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/MGOKQMNmZMM" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><br /></p>

<p><br /></p>

<h2 id="2016-talks">2016 Talks</h2>

<h3 id="abril-08-rob√≥tica-retos-y-soluciones-antonio-barrientos">(abril 08) Rob√≥tica: Retos y soluciones, Antonio Barrientos</h3>

<p>T√≠tulo: Rob√≥tica: Retos y soluciones</p>

<p>Ponente: Antonio Barrientos (UPM)</p>

<p>Resumen: La Rob√≥tica es una disciplina en pleno crecimiento. Firmemente asentada en el √°mbito industrial, especialmente en el sector automovil, lejos de estancarse, ha abordado nuevos retos en los sectores industriales, servicios y dom√©sticos.</p>

<p>¬øCu√°ndo?: 2016-04-08, 12h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSdfaOswcCpxgShO8qJ8Hxv5lR0CvskCNTK1ay7XAmSRRmkVbQ/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/traspas-robotica-abarrientos-2016.pdf">trasparencias</a> que se usaron.</p>

<p>La puedes disfrutar en el canal de YouTube de JdeRobot:</p>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/ZlCs67GZi5Y" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><br /></p>

<p><br /></p>

<h3 id="abril-05-t√©cnicas-de-autolocalizaci√≥n-en-3d-con-visi√≥n-monocular-eduardo-perdices">(abril 05) T√©cnicas de autolocalizaci√≥n en 3D con visi√≥n monocular, Eduardo Perdices</h3>

<p>T√≠tulo: T√©cnicas de autolocalizaci√≥n en 3D con visi√≥n monocular</p>

<p>Ponente: Eduardo Perdices (AFC ingenieros)</p>

<p>Resumen: En los √∫ltimos a√±os han surgido diversas t√©cnicas para la localizaci√≥n de robots, drones y dispositivos m√≥viles en entornos desconocidos, permitiendo obtener una localizaci√≥n precisa en 3D a la vez que se generan mapas del entorno en el que se encuentran. Este tipo de algoritmos han sido ya utilizados en la vida real en campos como la medicina, la educaci√≥n o los videojuegos. En esta charla veremos c√≥mo han ido evolucionando estas t√©cnicas a lo largo de los a√±os, destacando los algoritmos de MonoSLAM y PTAM, y explicaremos en detalle los √∫ltimos avances realizados en este campo de investigaci√≥n.</p>

<p>¬øCu√°ndo?: 2016-04-05, 18h</p>

<p>¬øD√≥nde?: Aula 170, departamental-II, campus de M√≥stoles de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLScYG1KInmrgbhRuZVC6xGqehfnmqFlzJ4ICJPhQVqa2_seV9w/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/autolocalizacion_edu-2016-traspas.pdf">trasparencias</a> que se usaron y el <a href="http://jderobot.org/store/jmplaza/uploads/charlas/autolocalizacion_edu-2016-audio.mp3">audio</a> grabado de la charla.</p>

<p><img src="/assets/images/activities/talks/autolocalizacionEdu2016.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="marzo-30-una-introducci√≥n-pr√°ctica-a-git-victor-arribas">(marzo 30) Una introducci√≥n Pr√°ctica a Git, Victor Arribas</h3>

<p>T√≠tulo: Una introducci√≥n Pr√°ctica a Git</p>

<p>Ponente: Victor Arribas (URJC)</p>

<p>Resumen: Introducci√≥n a Git desde un punto de vista pragm√°tico. El objetivo de la charla es motivacional. Ofrecer un por qu√© para usar Git, saber c√≥mo usarlo y saber cu√°ndo usarlo. Incluye casos pr√°cticos, as√≠ como herramientas de apoyo, simplificaci√≥n y atajos (te doy el punto de apoyo para que t√∫ muevas el mundo ‚Äì la ley de la palanca).</p>

<p>La charla no explica los aspectos elementales de Git. Para los novatos y no introducidos a Git se recomienda que echen un vistazo a estos tres recursos:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">*</span> Video explicaci√≥n de Git
  https://www.youtube.com/watch?v<span class="o">=</span>fBRE5zuYUlI
  <span class="o">(</span>videos m√°s relevantes: 1 y 3<span class="o">)</span>
<span class="k">*</span> √Årea de trabajo de Git
  http://marklodato.github.io/visual-git-guide/index-es.html
<span class="k">*</span> Libro official de Git <span class="o">(</span>espa√±ol<span class="o">)</span>
  https://git-scm.com/book/es/v2
</code></pre></div></div>

<p>¬øCu√°ndo?: 2016-03-30, 13h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSepUBeWEA3pjD7BX3PL338m1mxV2iGr4gm4BN8lxl_qo-qDkg/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/traspas-git-victor.pdf">trasparencias</a> que se usaron.</p>

<p><img src="/assets/images/activities/talks/charlaGit.jpg" width="100%" height="60%" /></p>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/8bIFJS8qRbo" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><br /></p>

<p><br /></p>

<h3 id="marzo-15-object-perception-life-cycle-from-detection-to-3d-shape-fitting-pablo-bustos">(marzo 15) Object perception life-cycle: from detection to 3D shape fitting, Pablo Bustos</h3>

<p>T√≠tulo: Object perception life-cycle: from detection to 3D shape fitting</p>

<p>Ponente: Pablo Bustos (Universidad de Extremadura)</p>

<p>Resumen: Object perception is a crucial aspect of current research in Social Robotics. In this talk we will describe our recent work on modeling the life-cycle of an object when it is perceived by an autonomous robot that has to locate, search, detect and recognize a household item. We follow an approach based on affordances to ask the following question, ¬øIf I believe the object in front of me is a table, how do I have to look at it so I can confirm it? To answer this question, the internal representation of the object will produce an adaptive plan of actions to validate the hypothesis of it being out there. These actions are visual routines that are chained to increasingly reduce the uncertainty of the potential object. Typical routines for a table object could be harris_corners or edge_following, and are called in the right order to the fixate the free parameters of the internal object. The goal is reached when a 3D geometric model is fitted to the object and tracked hereafter. We will describe work in progress towards building families of theses formal objects that know how to be perceived while adapting to occlusions and environmental changes.</p>

<p>¬øCu√°ndo?: 2016-03-15, 18h</p>

<p>¬øD√≥nde?: Aula 170, departamental-II, campus de M√≥stoles de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLScJcCTCGSd9Cu6msNwSWksnHyfFrfl1DasyVRKjyOoQZ0usGw/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/traspas-pbustos-2016.pdf">trasparencias</a> que se usaron.</p>

<p><img src="/assets/images/activities/talks/objectRecognition.png" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="enero-20-software-libre-en-rob√≥tica-proyecto-jderobot-jos√©-mar√≠a-ca√±as">(enero 20) Software libre en Rob√≥tica: proyecto JdeRobot, Jos√© Mar√≠a Ca√±as</h3>

<p>T√≠tulo: Software libre en Rob√≥tica: proyecto JdeRobot</p>

<p>Ponente: Jos√© Mar√≠a Ca√±as (URJC)</p>

<p>Resumen: Presentaremos la plataforma JdeRobot para la programaci√≥n de robots y de aplicaciones de visi√≥n artificial. Es un proyecto de software libre que est√° creciendo en funcionalidad y ha recibido financiaci√≥n de Google en 2015. Describiremos la arquitectura software subyancente orientada a componentes y el middleware de comunicaciones que emplea. Introduciremos los drivers de robots m√°s utilizados y varias herramientas rob√≥ticas que incluye: visores web, calibradores, la programaci√≥n visual con aut√≥matas‚Ä¶ Tambi√©n algunas otras piezas software en las que se apoya: simulador Gazebo, biblioteca PCL, openCV, ROS, etc. Adem√°s, daremos una panor√°mica de las aplicaciones m√°s recientes usando JdeRobot: dom√≥tica, realidad aumentada, manejo de drones, un robot m√≥vil en entorno industrial, kinect2, robot humanoide, monitorizaci√≥n de personas en 3D, etc..</p>

<p>¬øCu√°ndo?: 2016-01-20, 17h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSeKWf-nei0jtfL3aVMHKVil__HsX9ieuvf6FbaDO0Yi5n2UOw/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/jderobot-20160120.pdf">trasparencias</a> que se usaron.</p>

<p><img src="/assets/images/activities/talks/gsoc2015Portada.png" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="enero-18-t√©cnicas-de-optimizaci√≥n-en-visi√≥n-artificial-alberto-mart√≠n-francisco-rivas">(enero 18) T√©cnicas de optimizaci√≥n en visi√≥n artificial, Alberto Mart√≠n, Francisco Rivas</h3>

<p>T√≠tulo: T√©cnicas de optimizaci√≥n en visi√≥n artificial</p>

<p>Ponente: Alberto Mart√≠n (Verisk Analytics), Francisco Rivas (Verisk Analytics), Jos√© Mar√≠a Ca√±as</p>

<p>Resumen: Presentaremos varias t√©cnicas de optimizaci√≥n (Ajuste de m√≠nimos cuadrados, Descomposici√≥n en valores singulares -SVD-, RANSAC, Bundle Adjustment‚Ä¶) aplic√°ndolas tres o cuatro problemas. El objetivo es describir las t√©cnicas y hacer un an√°lisis de fortalezas y debilidades sobre ejemplos concretos. Comentaremos tiempos t√≠picos de c√≥mputo, precisi√≥n, robustez a ruido t√©rmico, robustez a d√≠scolos (outliers), etc.. Empezaremos por ajustar la l√≠nea que subyace en un conjunto de puntos 2D con ruido. Continuaremos con ajustar el plano que subyace a un conjunto de puntos 3D con ruido. Abordaremos el problema del registro visual: conociendo los puntos 3D de un patr√≥n y en qu√© p√≠xeles aparecen en la imagen, estimar la posici√≥n y orientaci√≥n 3D de la c√°mara. Conoci√©ndo estas t√©cnicas de optimizaci√≥n podr√°s usarlas como herramientas en problemas de visi√≥n, por ejemplo visualSLAM.</p>

<p>¬øCu√°ndo?: 2016-01-18, 18h</p>

<p>¬øD√≥nde?: Aula 170, departamental-II, campus de M√≥stoles de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSd-bNpWJDCzMrt7mrA4g_E8T9RCVwNLq10KGGQJC9DLq7ux8A/viewform">aqu√≠</a></p>

<p>Aqu√≠ tienes las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/alberto_fran_jm-optimizacion.pdf">trasparencias</a> que hemos usado.</p>

<p><img src="/assets/images/activities/talks/optimizacionError.png" width="45%" height="60%" />
<img src="/assets/images/activities/talks/charlaOptimizacion2016.jpg" width="45%" height="60%" /></p>

<p><br /></p>

<h3 id="enero-14-tecnolog√≠as-web-en-rob√≥tica-aitor-mart√≠nez">(enero 14) Tecnolog√≠as web en Rob√≥tica, Aitor Mart√≠nez</h3>

<p>T√≠tulo: Tecnolog√≠as Web en rob√≥tica</p>

<p>Ponente: Aitor Mart√≠nez (URJC)</p>

<p>Resumen: ¬øPuedes teleoperar un drone o ver los datos de una Kinect desde el navegador de tu tel√©fono m√≥vil? Html5, Javascript (JQuery, Bootstrap‚Ä¶), ICE-JS pueden ayudarte a ello. Las tecnolog√≠as web han incrementado enormemente su rendimiento y funcionalidad en los √∫ltimos a√±os. Presentaremos los desarrollos m√°s recientes en JdeRobot conectando navegadores web con los drivers de robots y sensores, directamente. Con ellos la interfaz gr√°fica de una aplicaci√≥n rob√≥tica puedes programarla en Javascript y es multiplataforma, ya no hay que programar un GUI para cada sistema operativo.</p>

<p>¬øCu√°ndo?: 2016-01-14, 17h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p>Como siempre, es abierta. Ap√∫ntate <a href="https://docs.google.com/forms/d/e/1FAIpQLSedP0bjE-P_zZy6Is9p_K7POFj3C5pdcJybMcO4kfM5PzrAfQ/viewform">aqu√≠</a></p>

<p>Tienes aqu√≠ las <a href="http://jderobot.org/store/jmplaza/uploads/charlas/tecnologias_web-2015.pdf">trasparencias</a> que se usaron.</p>

<p><img src="/assets/images/activities/talks/tfgAitor.png" width="100%" height="60%" /></p>

<p><br /></p>

<p><br /></p>

<h2 id="2015-talks">2015 Talks</h2>

<h3 id="aplicaciones-de-autolocalizaci√≥n-visual-y-realidad-aumentada-yazmin-cumberbirch-y-daniel-azuara">Aplicaciones de Autolocalizaci√≥n visual y Realidad Aumentada, Yazmin Cumberbirch y Daniel Azuara</h3>

<p>T√≠tulo: Aplicaciones de Autolocalizaci√≥n visual y Realidad Aumentada</p>

<p>Ponente: Yazmin Cumberbirch (Telef√≥nica Global Solutions) y Daniel Azuara (Telef√≥nica)</p>

<p>Resumen: En la √∫ltima d√©cada, las aplicaciones visuales se han hecho cada vez mayor hueco entre las aplicaciones punteras. La posibilidad de que un elemento que contiene una c√°mara pueda conocer su posici√≥n en un mundo conocido, solo haciendo uso de las im√°genes de la c√°mara que las captura abre paso a una gran gama de aplicaciones de realidad aumentada, que pueden utilizar dicha posici√≥n calculada de la c√°mara para proyectar, sobre el mundo real, figuras virtuales que interact√∫an con dicho mundo. La interacci√≥n con el mundo puede ser tan compleja como quiera la imaginaci√≥n del desarrollador y las librer√≠as disponibles, as√≠ como su exportaci√≥n a plataformas m√≥viles para una mayor portabilidad. En esta charla, por una parte hablaremos de lo que es la autolocalizaci√≥n visual, as√≠ como distintas formas de realizarla, y por otra, de una serie de aplicaciones de realidad aumentada que se han desarrollado en la URJC con JdeRobot, utilizando como base las t√©cnicas de autolocalizaci√≥n visual comentadas.</p>

<p>¬øCu√°ndo?: 2015-06-23, 18h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p><img src="/assets/images/activities/talks/charlaYazmin.jpg" width="100%" height="60%" /></p>

<p><br /></p>

<h3 id="programando-drones-en-el-simulador-gazebo-daniel-yag√ºe">Programando drones en el simulador Gazebo, Daniel Yag√ºe</h3>

<p>T√≠tulo: Programando drones en el simulador Gazebo</p>

<p>Ponente: Daniel Yag√ºe (Indra)</p>

<p>Resumen: En los √∫ltimos a√±os han aparecido varias plataformas comerciales de robots a√©reos (drones) a precio asequible, se han popularizado y se ha disparado el abanico de aplicaciones que estos robots abren: juegos, grabaci√≥n de escenas para cine o anuncios, transporte de mercanc√≠as, vigilancia de instalaciones, etc. El inter√©s en este tipo de robots es enorme actualmente y se est√°n explorando las posibilidades reales de nuevas aplicaciones. Por ejemplo, empresas punteras como Google (<a href="https://www.youtube.com/watch?v=cRTNvWcx9Oo">Project Wing</a>) o Amazon (<a href="https://www.youtube.com/watch?v=98BIu9dpwHU">Prime Air</a>) han ense√±ado prototipos de drones que llevan mercanc√≠a de un lugar a otro. Un tipo de drone muy exitoso son los cuadric√≥pteros, que incorporan un sistema de vuelo con cuatro h√©lices y motores. La inteligencia y funcionalidad reside en su software, en los programas que ejecuta. Para preparar este software y depurarlo sin riesgo son muy √∫tiles los simuladores. En esta charla se presenta el soporte para estos cuadric√≥pteros en JdeRobot utilizando el simulador Gazebo y varias aplicaciones con ellos. Por un lado, los plugins de Gazebo que permiten a las aplicaciones de JdeRobot conectarse con los sensores y actuadores del cuadric√≥ptero. Por otro, varios ejemplos de navegaci√≥n del cuadric√≥ptero programados utilizando ese soporte: seguir una carretera, navegaci√≥n guiada por posici√≥n, exploraci√≥n aut√≥noma dentro de un per√≠metro‚Ä¶ Esta infraestructura se ha usado con √©xito en el <a href="http://jderobot.org/Programacion-de-drones">curso URJC de programaci√≥n de drones</a> y se usar√° en el <a href="http://jderobot.org/Campeonato-programacion-de-robots">campeonato abierto de programaci√≥n de drones</a> que se celebra en unas semanas.</p>

<p>¬øCu√°ndo?: 2015-06-08, 17h</p>

<p>¬øD√≥nde?: Laboratorio de Rob√≥tica: Lab III, aula 3104, campus de Fuenlabrada de la URJC</p>

<p><br /></p>

<h3 id="un-proyecto-exitoso-de-ingenier√≠a-robot-m√≥vil-industrial-aut√≥nomo-josemar√≠a-ca√±as">Un proyecto exitoso de ingenier√≠a: robot m√≥vil industrial aut√≥nomo, JoseMar√≠a Ca√±as</h3>

<p>T√≠tulo: Un proyecto exitoso de ingenier√≠a: robot m√≥vil industrial aut√≥nomo</p>

<p>Ponente: Jos√© Mar√≠a Ca√±as (URJC)</p>

<p>Resumen: La robotizaci√≥n es una tendencia creciente en los escenarios industriales y de log√≠stica. Los brazos manipuladores son los m√°s extendidos pero con los recientes avances se est√°n abriendo paso robots con ruedas capaces de moverse de modo seguro y transportar mercanc√≠as por s√≠ mismos de un punto a otro en cierto entorno. Por ejemplo, Amazon equipa sus nuevos centros log√≠sticos con una flota de robots que transportan los pedidos de modo autom√°tico y eficiente. Estos robots incorporan capacidades de navegaci√≥n y autolocalizaci√≥n aut√≥nomas. En esta charla se presentar√° el caso de √©xito de un robot m√≥vil aut√≥nomo programado por el Grupo de Rob√≥tica de la URJC para un escenario industrial donde la robustez es requisito fundamental. El robot se mueve para transportar cargas y utiliza sensores RGBD, tipo Kinect, para autolocalizarse, guiarse y percibir obst√°culos.</p>

<p>¬øCu√°ndo?: 2015-04-17, 17h</p>

<p>¬øD√≥nde?: Aulario II, aula 205, campus de Fuenlabrada de la URJC</p>

<p><br /></p>

<h3 id="simplificando-el-desarrollo-software-con-cmake-lroberto-morales">Simplificando el desarrollo software con CMake, L.Roberto Morales</h3>

<p>T√≠tulo: Simplificando el desarrollo software con CMake</p>

<p>Ponente: Luis Roberto Morales (Blamar Automatizaci√≥n Y Control)</p>

<p>Resumen: Conforme un proyecto software adquiere mayor funcionalidad y complejidad, se complican tareas de desarrollo y mantenimiento como pueden ser la generaci√≥n de binarios, paquetes de distribuci√≥n y m√≥dulos de pruebas. En esta presentaci√≥n se tratar√° en cierta profundidad qu√© es y c√≥mo funciona la herramienta Cmake (<a href="https://cmake.org/">http://www.cmake.org/</a>). Es una herramienta multiplataforma destinada a simplificar y automatizar algunas de estas tareas, y es utilizada en el desarrollo de la plataforma rob√≥tica JdeRobot as√≠ como de otros muchos proyectos de software (Netflix, KDE, mySQL‚Ä¶).</p>

<p>¬øCu√°ndo?: 2015-04-10, 17h</p>

<p>¬øD√≥nde?: Aulario II, aula 207, campus de Fuenlabrada de la URJC</p>

<p>Transparencias: <a href="http://jderobot.org/store/lr.morales/uploads/slides/CMake-talk.pdf">CMake-talk</a></p>

<p>Ejemplos: <a href="http://jderobot.org/store/lr.morales/uploads/slides/CMake-talk.tgz">CMake-examples</a></p>

<div class="embed-container">
  <iframe src="https://www.youtube.com/embed/BnbJRuHUg2Y" width="700" height="480" frameborder="0" allowfullscreen="">
  </iframe>
</div>

<p><br /></p>

<p><br /></p>

<h2 id="2014-talks">2014 Talks</h2>

<h3 id="robots-a√©reos-en-la-urjc-jorge-cano-daniel-yag√ºe-alberto-mart√≠n-urjc">Robots a√©reos en la URJC, Jorge Cano, Daniel Yag√ºe, Alberto Mart√≠n (URJC)</h3>

<p>T√≠tulo: Robots a√©reos en la URJC</p>

<p>Ponente: <a href="http://ieeesb.etsit.urjc.es/proyectos/wiki/Quadrotor">Jorge Cano</a>, <a href="http://jderobot.org/Daniyague-pfc">Daniel Yag√ºe</a> y <a href="http://jderobot.org/Amartinflorido-tfg">Alberto Mart√≠n</a></p>

<p>Resumen: La tecnolog√≠a rob√≥tica proporciona cada vez m√°s aplicaciones y productos a la sociedad: aspiradoras rob√≥ticas, drones, brazos robotizados en factor√≠as de coches, en embalaje, robots que ayudan a cirujanos, etc.. En esta exhibici√≥n se presentar√°n varios trabajos sobre robots a√©reos desarrollados en la Universidad Rey Juan Carlos. Entre ellos un cuadric√≥ptero construido por estudiantes de la Rama IEEE en la URJC (<a href="http://ieeesb.etsit.urjc.es/proyectos/wiki/Quadrotor">Grupo Aerologies</a>), otro cuadric√≥ptero real (ArDrone) que <a href="http://jderobot.org/Amartinflorido-tfg">navega aut√≥nomamente siguiendo objetos</a> y otro simulado que <a href="http://jderobot.org/Daniyague-pfc#Third_attempt">sigue una carretera usando visi√≥n</a> y explora una zona en busca de objetos relevantes en tierra. Se describir√° brevemente el hardware de los robots, sus sensores, as√≠ como el software y los algoritmos que le dan inteligencia.</p>

<p>When: 2014-11-28, 18h</p>

<p>Where: Laboratorio de Rob√≥tica URJC (archivo 7, edificio biblioteca), campus de Fuenlabrada de la URJC</p>

<p>Slides: <a href="http://jderobot.org/store/jmplaza/uploads/Aerologies.pdf">Aerologies</a></p>

<p><img src="/assets/images/activities/talks/charlaUAVs20141128.jpg" width="100%" height="60%" /></p>

<p>This talk-exhibition has been celebrated as an event inside the <a href="http://www.eu-robotics.net/cms/index.php?idart=3202">European Robotics Week</a>.</p>

<p><br /></p>

<h3 id="surveillance-4-dom√≥tica-en-jderobot-daniel-castellano-ingenier√≠a-de-software-avanzado-sa">Surveillance 4, dom√≥tica en JdeRobot, Daniel Castellano (Ingenier√≠a de Software Avanzado, S.A.)</h3>

<p>T√≠tulo: Surveillance 4, dom√≥tica en JdeRobot</p>

<p>Ponente: <a href="http://jderobot.org/D.castellanob-pfc">Daniel Castellano</a></p>

<p>Resumen: La dom√≥tica ya no es algo que s√≥lo pueda verse en pel√≠culas y casas de revista. Cada vez est√° es m√°s util y est√° m√°s extendida. Por ello JdeRobot (plataforma de programaci√≥n de software libre) ha implementado entre sus componentes a Surveillance, el cual permite en su √∫ltima versi√≥n integrar sensores (temperatura, luz, etc.), alarmas (puerta abierta, inundaci√≥n‚Ä¶), actuadores (encendido y apagado de luces) y videovigilancia (streaming de v√≠deo). Las posibilidades que ofrece este componente son muy grandes, desde las t√≠picas de la dom√≥tica (ahorro de energ√≠a, comodidad, etc.) hasta la integraci√≥n con otros componentes de Jderobot para el cuidado de ancianos. En esta charla explicaremos las bases de funcionamiento de Surveillance, las funcionalidades implementadas y las l√≠neas de actuaci√≥n futuras.</p>

<p>When: 2014-02-28, 18:30h</p>

<p>Where: Laboratorio de Rob√≥tica URJC (archivo 7, edificio biblioteca), campus de Fuenlabrada de la URJC</p>

<p><a href="http://jderobot.org/store/jmplaza/uploads/charlas/daniel-survillance-20140228.pdf">slides</a></p>

<p><br /></p>

<h3 id="vision-para-rob√≥tica-geometr√≠a-y-entendimiento-javier-civera-uzaragoza">Vision para Rob√≥tica: Geometr√≠a y entendimiento, Javier Civera (U.Zaragoza)</h3>

<p>T√≠tulo: Vision para Rob√≥tica: Geometr√≠a y entendimiento</p>

<p>Ponente: <a href="http://webdiis.unizar.es/~jcivera/">Javier Civera</a></p>

<p>Resumen: El modelado del entorno de un robot a partir de informaci√≥n sensorial es una de las piezas claves para el desarrollo de robots aut√≥nomos capaces de interactuar y navegar de manera segura en dicho espacio. Algunas tareas rob√≥ticas (por ejemplo la navegaci√≥n) precisan √∫nicamente informaci√≥n geom√©trica de entorno. Los modelos geom√©tricos del entorno han sido ampliamente estudiados, en gran parte bajo el nombre de Simultaneous Localization and Mapping (SLAM). Sin embargo, la realizaci√≥n de tareas m√°s complejas (por ejemplo encontrar un objeto y llevarlo a una persona) requieren un mayor entendimiento de la escena; es decir, modelos de nivel sem√°ntico m√°s alto: ¬øC√≥mo reconozco el objeto? ¬øD√≥nde es m√°s probable encontrarlo? ¬øD√≥nde est√° la persona? En esta presentaci√≥n se expondr√°n una serie de trabajos recientes relacionados con la construcci√≥n de modelos geom√©tricos y de alto nivel sem√°ntico a partir de informaci√≥n visual; as√≠ como las relaciones entre ambos tipos de modelos y su utilidad para rob√≥tica m√≥vil. Se analizar√°n tambi√©n los avances recientes en hardware y recursos computacionales (tarjetas gr√°ficas, computaci√≥n y almacenamiento en la nube) y su uso en percepci√≥n rob√≥tica.</p>

<p>When: 2014-02-04, 16h</p>

<p>Where: Aula 170, departamental-II, campus de M√≥stoles de la URJC</p>

<p><br /></p>

<h2 id="2013-talks">2013 Talks</h2>

<h3 id="programando-robots-humanoides-con-aut√≥matas-de-estado-finito-borja-men√©ndez-urjc">Programando robots humanoides con aut√≥matas de estado finito, Borja Men√©ndez (URJC)</h3>

<p>T√≠tulo: VisualHFSM4: Programando robots humanoides con aut√≥matas de estado finito</p>

<p>Ponente: <a href="http://jderobot.org/Bmenendez-tfm">Borja Men√©ndez</a></p>

<p>Resumen: Uno de los campos de mayor inter√©s en rob√≥tica es el de los robots humanoides. Prototipos como el Asimo de Honda o el Fujitsu HOAP-3 son la base de muchos esfuerzos en investigaci√≥n, varios de ellos para replicar tanto la inteligencia como la maniobrabilidad humanas. Sus aplicaciones son muy variadas: en terapias de enfermos de Alzheimer aprovechando su f√°cil aceptaci√≥n por humanos, en labores de rescate (por ejemplo Darpa Robotics Challenge -DRC-) o en demostradores tecnol√≥gicos como jugar un partido de f√∫tbol (RoboCup). Existen herramientas para facilitar su programaci√≥n y en esta charla contaremos dos de ellas que hemos desarrollado para el robot humanoide Nao. En primer lugar el soporte para el Nao dentro del simulador Gazebo. Los simuladores ofrecen entornos virtuales y emulan un mundo lo m√°s realista posible; Gazebo es el simulador de referencia para ROS y para el DRC, ampliamente usado en la comunidad rob√≥tica. En segundo lugar, una herramienta que permite programar la inteligencia del humanoide usando aut√≥matas de estado finito: VisualHFSM. (M√°s informaci√≥n en <a href="http://jderobot.org/Bmenendez-tfm">http://jderobot.org/Bmenendez-tfm</a>).</p>

<p>When: 2013-11-29, 18h</p>

<p>Where: Aula 303, departamental-III, campus de Fuenlabrada</p>

<p><br /></p>

<h3 id="robots-industriales-aut√≥nomos-proyecto-autonav-alejandro-hern√°ndez-dta">Robots industriales aut√≥nomos: proyecto AutoNav, Alejandro Hern√°ndez (DTA)</h3>

<p>T√≠tulo: Robots industriales aut√≥nomos: proyecto AutoNav</p>

<p>Ponente: <a href="http://jderobot.org/Ahcorde-tfm">Alejandro Hern√°ndez</a></p>

<p>Resumen: En los √∫ltimos a√±os los robots aut√≥nomos han salido de los laboratorios y est√°n us√°ndose en otros escenarios de manera creciente. La aspiradora rob√≥tica Roomba en el √°mbito dom√©stico y los veh√≠culos aut√≥nomamente guiados (AGV) en √°mbito industrial son ejemplos de √©xito. En esta charla el ingeniero Alejandro Hern√°ndez, de la empresa DTA, contar√° los etalles y la tecnolog√≠a rob√≥tica desarrollada en el proyecto AutoNav, de construcci√≥n y programaci√≥n de un robot aut√≥nomo capaz de arrastrar cargas pesadas. Describir√° las t√©cnicas de navegaci√≥n local, navegaci√≥n global, autolocalizaci√≥n desarrolladas. Tambi√©n se comentar√°n las aplicaciones realizadas para teleoperar desde una tableta Android al robot y el entorno de simulaci√≥n creado para ajustar los algoritmos antes de llevarlos a la plataforma real. (M√°s informaci√≥n en <a href="http://jderobot.org/AutoRob">http://jderobot.org/AutoNav</a>)</p>

<p>When: 2013-11-08, 18h</p>

<p>Where: Sala de Grados, departamental-I, campus de Fuenlabrada</p>

<p><a href="http://jderobot.org/store/jmplaza/uploads/charlas/alex-autonav-20131108.pdf">slides</a></p>

<p><br /></p>

<h3 id="automatic-vehicle-classification-based-on-vision-redouane-kachach-urjc">Automatic vehicle classification based on vision, Redouane Kachach (URJC)</h3>

<p>T√≠tulo: Monitorizaci√≥n tr√°fico rodado con visi√≥n (TrafficMonitor)</p>

<p>Ponente: <a href="http://jderobot.org/Redo-phd">Redouane Kachach</a></p>

<p>Resumen: Redouane Kachach, que est√° haciendo su tesis doctoral sobre ello, nos contar√° los algoritmos de visi√≥n que subyacen dentro de la aplicaci√≥n TrafficMonitor. Son los que permiten al programa contar los veh√≠culos que pasan por una carretera, estimar su velocidad y clasificarlos (moto, coche, autobus, furgoneta, etc.). TrafficMonitor es una aplicaci√≥n que usa Jderobot y tiene como entrada las im√°genes de una c√°mara encima de una carretera. Hay m√°s detalles y videos ilustrativos <a href="http://jderobot.org/index.php/TrafficMonitor">aqu√≠</a>.</p>

<p>When: 2013-07-12, 18:30h</p>

<p>Where: Laboratorio de Rob√≥tica URJC (archivo 7, edificio biblioteca), campus de Fuenlabrada</p>

<p><a href="http://jderobot.org/store/jmplaza/uploads/charlas/redo-traffic_monitor-20130712.pdf">slides</a></p>

<p><br /></p>

<h3 id="advances-in-3d-data-processing-and-3d-cameras-miguel-cazorla-ualicante">Advances in 3D data processing and 3D cameras, Miguel Cazorla (U.Alicante)</h3>

<p>T√≠tulo: Avances en manejo de datos 3D y c√°maras RGBD</p>

<p>Ponente: <a href="http://www.dccia.ua.es/~miguel/">Dr. Miguel Cazorla</a></p>

<p>Resumen: Actualmente, gracias al dispositivo Kinect, el uso de c√°maras RGBD ha supuesto un gran avance tanto en el campo de la rob√≥tica como de la visi√≥n artificial. Sin embargo, el volumen de datos proporcionado por este dispositivo es enorme, por lo que es necesario disponer de m√©todos para reducir esta cantidad de informaci√≥n y hacerlo en un tiempo razonable. En esta charla vamos a ver varios m√©todos que hemos desarrollado para conseguir este fin. Por un lado, describiremos el uso de una red neuronal (Growing Neural Gas) que permite preservar la topolog√≠a de los datos y reducir considerablemente su volumen. Sin embargo, esta red no es precisamente r√°pida, por lo que se propone el uso de GPUs para reducir su coste temporal. Por otro lado, describiremos un par de m√©todos de extracci√≥n de caracter√≠sticas para 3D, aplicados a tareas rob√≥ticas. Por √∫ltimo, presentaremos un m√©todo de ‚Äúcompresi√≥n‚Äù de datos 3D basado en planos y que permite tener en cuenta el color presente en la escena.</p>

<p>When: 2013-05-13, 11:30h</p>

<p>Where: Laboratorio de Rob√≥tica URJC (archivo 7, edificio biblioteca), campus de Fuenlabrada</p>

<p><a href="http://jderobot.org/store/jmplaza/uploads/charlas/cazorla-traspas2013.pdf">slides</a></p>

<p><br /></p>

<h3 id="construcci√≥n-mapas-visuales-en-tiempo-real-jos√©-m-mart√≠nez-montiel-uzaragoza">Construcci√≥n Mapas Visuales en Tiempo-Real, Jos√© M. Mart√≠nez Montiel (U.Zaragoza)</h3>

<p>T√≠tulo: Construcci√≥n de mapas visuales en tiempo real</p>

<p>Ponente: <a href="http://webdiis.unizar.es/~josemari/">Jos√© M. Mart√≠nez Montiel</a></p>

<p>Resumen: Es un resultado bien conocido que a partir √∫nicamente de una secuencia de im√°genes tomadas por una c√°mara m√≥vil que observa una escena puede estimarse tanto un mapa dicha escena, como la trayectoria seguida por la c√°mara. Este problema conocido en rob√≥tica mediante el acr√≥nimo SLAM visual (Simultaneous sensor Location And Mapping) es uno de los m√°s investigados en rob√≥tica m√≥vil porque es una de las capacidades b√°sicas para la operaci√≥n aut√≥noma de un robot. El seminario cubrir√° una panor√°mica de los m√©todos de SLAM visual comenzando con los m√©todos focalizados en la estimaci√≥n de la geometr√≠a de la escena en tiempo real. Posteriormente se abordar√° el contenido sem√°ntico del mapa estimado, considerando la inclusi√≥n de objetos reconocidos en los mapas. Tambi√©n se presentar√°n m√©todos de SLAM en aplicaciones de endoscopia m√©dica y en escenas no r√≠gidas.</p>

<p>When: 2013-04-18, 16h</p>

<p>Where: Sal√≥n de Grados del departamental-II, URJC, campus de M√≥stoles</p>

<p><a href="http://jderobot.org/store/jmplaza/uploads/charlas/montiel-traspas.pdf">slides</a></p>

<p><br /></p>

<h3 id="jderobot_51-maikel-gonz√°lez-urjc">JdeRobot_5.1, Maikel Gonz√°lez (URJC)</h3>

<p>T√≠tulo: Plataforma JdeRobot 5.1 para desarrollo de aplicaciones rob√≥ticas</p>

<p>Ponente: <a href="http://jderobot.org/Mikel-pfc-itis">Maikel Gonz√°lez</a></p>

<p>Resumen: En esta charla se comentar√°n los aportes principales de la nueva versi√≥n de esta plataforma. Especialmente el uso de cmake como herramienta en la cadena de compilaci√≥n sustituyendo a autotools, el dise√±o de la paqueteria debian renovado y algunos componentes nuevos o refinados respecto de los existentes en Jderobot-5.0 (gazeboserver, basic_component, introrob, etc.). Adem√°s de nosotros la est√°n usando para pr√°cticas alumnos de dos m√°steres de esta universidad.</p>

<p>When: 2013-03-15, 18:30h</p>

<p>Where: Laboratorio de Rob√≥tica URJC (archivo 7, edificio biblioteca), campus de Fuenlabrada</p>

<p><a href="http://jderobot.org/store/jmplaza/uploads/charlas/maykel_gonzalez-jderobot5.1-slides.pdf">slides</a></p>

<p><br /></p>

<h3 id="localization-in-unknown-environments-using-computer-vision-eduardo-perdices-urjc">Localization in unknown environments using computer vision, Eduardo Perdices (URJC)</h3>

<p>T√≠tulo: Localization in unknown environments using computer vision</p>

<p>Ponente: <a href="http://jderobot.org/Eperdices_PhD">Eduardo Perdices</a></p>

<p>Resumen: Aplicaci√≥n pr√°ctica de la visi√≥n artificial para calcular la localizaci√≥n de una c√°mara en un entorno desconocido en tiempo real. Se utiliza un algoritmo conocido como MonoSLAM, que es capaz de calcular la trayectoria realizada por una c√°mara y de generar autom√°ticamente un mapa del entorno utilizando un filtro extendido de Kalman (EKF). Es una oportunidad de conocer de modo distentido varios algoritmos de procesamiento visual muy chulos (echad un ojo a [1] para alg√∫n video del sistema funcionando) y la tecnolog√≠a alrededor. Inspiradora.</p>

<p>When: 2013-03-01, 18:30h</p>

<p>Where: Laboratorio de Rob√≥tica URJC (archivo 7, edificio biblioteca), campus de Fuenlabrada</p>

<p><a href="http://jderobot.org/store/jmplaza/uploads/charlas/eperdices-monoslam.pdf">slides</a></p>

<p><br /></p>

<h3 id="herramientas-programaci√≥n-en-el-entorno-jderobot-cmake-subversion-sftp-alejandro-hern√°ndez-and-borja-men√©ndez-urjc">Herramientas programaci√≥n en el entorno JdeRobot: CMake, subversion, sftp. Alejandro Hern√°ndez and Borja Men√©ndez (URJC)</h3>

<p>T√≠tulo: Herramientas programaci√≥n en el entorno JdeRobot: CMake, subversion, sftp</p>

<p>Ponente: <a href="http://jderobot.org/Ahcorde-tfm">Alejandro Hern√°ndez</a> <a href="http://jderobot.org/Bmenendez-tfm">Borja Men√©ndez</a></p>

<p>Resumen: En esta charla se presenta la plataforma JdeRobot para la programaci√≥n aplicaciones de rob√≥tica, visi√≥n computacional y sistemas sensoriales inteligentes. Tambi√©n se ense√±a a manejar varias herramientas de desarrollo √∫tiles en proyectos software y que se emplean con asiduidad en la comunidad de JdeRobot. Por ejemplo los repositorios subversion, la cadena de compilaci√≥n con CMAKE y el manejo de sftp</p>

<p>When: 2013-02-25, 18:30h</p>

<p>Where: Laboratorio de Rob√≥tica URJC (archivo 7, edificio biblioteca), campus de Fuenlabrada</p>

<p>Slides: <a href="http://jderobot.org/store/jmplaza/uploads/charlas/alexborja-jderobot.pdf">JdeRobot</a> <a href="http://jderobot.org/store/jmplaza/uploads/charlas/alexborja-cmake.pdf">cmake</a> <a href="http://jderobot.org/store/jmplaza/uploads/charlas/alexborja-subversion.pdf">subversion</a> <a href="http://jderobot.org/store/jmplaza/uploads/charlas/alexborja-sftp.pdf">sftp</a></p>

:ET