---
permalink: /activities/gsoc/2017
title: "GSoC 2017"


sidebar:
  nav: "docs"

toc: true
toc_label: "TOC GSoC-2017"
toc_icon: "cog"

<!--- layout: archive --->

<!--- classes: wide --->
---


JdeRobot is a software development suite for robotics, home-automation and computer vision applications. These domains include sensors (for instance, cameras), actuators, and intelligent software in between. It has been designed to help in programming such intelligent software. It is written in C++ language and provides a distributed component-based programming environment where the application program is made up of a collection of several concurrent asynchronous components. Each component may run in different computers and they are connected using ICE communication middleware. Components may be written in C++, Python, Java... and all of them interoperate through explicit ICE interfaces.

JdeRobot simplifies the access to hardware devices from the control program. Getting sensor measurements is as simple as calling a local function, and ordering motor commands as easy as calling another local function. The platform attaches those calls to the remote invocation on the components connected to the sensor or the actuator devices. They can be connected to real sensors and actuators or simulated ones, both locally or remotely using the network. Those functions build the API for the Hardware Abstraction Layer. The robotic application get the sensor readings and order the actuator commands using it to unfold its behavior. Several driver components have been developed to support different physical sensors, actuators and simulators. The drivers are used as components installed at will depending on your configuration. They are included in the official release. 


# Selected students

* <img src="/assets/images/activities/gsoc/nigel.jpg" style="width:200px;">

[Nigel Fernandez](https://wiki.jderobot.org/Ni9elf-colab) has worked on Project #8.

* <img src="/assets/images/activities/gsoc/okan-asik.jpg" style="width:200px;">

[Okan Asik](https://wiki.jderobot.org/Okanasik-colab) has worked on Project #4.

* <img src="/assets/images/activities/gsoc/sepehr2.jpg" style="width:200px;">

[S.Mehdi Mohaimanian](https://wiki.jderobot.org/Deep_Reinforcement_Learning_in_Robotics) has worked on Project #3.

* <img src="/assets/images/activities/gsoc/raul-perula.jpg" style="width:200px;">

[Raúl Pérula](https://wiki.jderobot.org/Raulperula-colab) has worked on Project #5.



# Ideas list

This open source project needs further development in these topics: 

## Project #1: TeachingRobotics: a Formula-1 race in Gazebo-7

**Brief Explanation**: [Teaching Robotics](https://jderobot.org/Robotics-Academy) is an academic framework for teaching robotics and computer vision. It includes several exercises where each one includes a Python application that connects to the real or simulated robot and provides a template that the students have to fill with their code for the robot behavior. There are two exercises with a Formula-1 car in Gazebo-7: one about the [car following a line](https://jderobot.github.io/RoboticsAcademy/portfolio/follow_line/) and another about the [car avoiding obstacles](https://jderobot.github.io/RoboticsAcademy/portfolio/obstacle_avoidance/) while the race circuit. This project aims to develop a new exercise (and solution) about two cars racing in the circuit, where there are also several dummy cars. The final student will have access to the laser sensor, the onboard camera on the car, its throttle and steering wheel.

<img src="/assets/images/activities/gsoc/circuito-f1.jpg"> 

<img src="/assets/images/activities/gsoc/circuitoF1-5.jpg"> 

<br/>

**Expected results:** a new robotics exercise in Gazebo-7.

**Knowledge Prerequisite:** Python programming skills 

**Mentors:** [Jose María Cañas](http://gsyc.es/jmplaza) (jmplaza AT gsyc.es) and Francisco Pérez (f.perez475 AT gmail.com)


## Project #2: TeachingRobotics: Localization exercise from a given map

**Brief Explanation**: [Teaching Robotics](https://jderobot.org/Robotics-Academy) is an academic framework for teaching robotics and computer vision. It includes several exercises where each one includes a Python application that connects to the real or simulated robot and provides a template that the students have to fill with their code for the robot algorithms. The goal of this project is to develop a new exercise (and solution) about localization of an autonomous wheeled robot which moves along a known scenario in Gazebo7. The robot has laser sensor and RGBD sensor. MonteCarlo localization algorithm will be the main approach. The application will include visualization of particles and step by step execution. 

<img src="/assets/images/activities/gsoc/particle_filter.png" style="height:300px;"> 

<img src="/assets/images/activities/gsoc/siftmcl.gif"> 

<br/>

**Expected results:** a new robotics exercise in Gazebo-7.

**Knowledge Prerequisite:** Python programming skills 

**Mentors:** [Jose María Cañas](http://gsyc.es/jmplaza) (jmplaza AT gsyc.es)



## Project #3: Reinforcement Learning in JdeRobot: OpenAI Gym and Gazebo

**Brief Explanation**: The main idea of this project is the development of an extension for OpenAI gym to introduce the Reinforcement Learning in JdeRobot framework with the Gazebo simulator. Once the extension has been developed the second part of the project consists in learning with such OpenAI gym extension a navigation behavior for a simulated Turtlebot robot (or drone or autonomous car). 

<img src="/assets/images/activities/gsoc/gsoc207.png"> 

<br/>

**Expected results:** an extension for OpenAI gym for robotics using JdeRobot and Gazebo and  the implementation of a behaviour using Deep Convolutional Q-Learning.

**Knowledge Prerequisite:** python programming, computer vision, machine learning, gazebo, robotics

**Mentors:** Alberto Martín (almartinflorido AT gmail.com)


## Project #4: Automatic generation of ROS node with an automaton using VisualHFSM tool

**Brief Explanation**: VisualHFSM is a visual programming tool which uses hierarchical finite state machines for automatically generating code. This functionality makes easier the programming of complex behaviors for different types of robots such as the Kobuki or the ArDrone. This tool automatically creates a C++ JdeRobot component or a Python JdeRobot component that implements the Hierachical FSM, which has been designed visually. Such component graphically shows the current state of the HFSM in runtime, which is very convenient to debug the automata. A more detailed description can be found [here](http://wiki.jderobot.org/index.php/Tools#VisualHFSM), different examples and applications made with it can be found [here](http://wiki.jderobot.org/index.php/Running_JdeRobot#VisualHFSM).

Although VisualHFSM is a mature and ready to use, there is still place for improvements. This proposal seeks to add modifications to this tool for achieving a more powerful version which provides more functionalities and flexibility. The main goal of this project is to generate a ROS application which implements the automaton and may connect to other ROS driver nodes. Other proposed modifications are: refactor visualHFSM GUI from GTK library to Qt5, and adding new features for improving the real-time debugging process. 


<img src="/assets/images/activities/gsoc/visualHFSM-example.png"> 

<br/>


**Expected results:** a new release of visualHFSM tool.

**Knowledge Prerequisite:** C++ programming skills, ROS robotic middleware

**Mentors:** Samuel Rey (samuel.rey.escudero AT gmail.com)


## Project #5: Translation of a Scratch program to ROS python component

**Brief Explanation**: [Scratch](https://scratch.mit.edu/ Scratch) is a free visual programming language used in children education, to teach them basic programming. It is composed of graphical building blocks (instructions) that must be visually connected to build the program. The idea here is to take benefit of our experience translating from a graphical description of a program in visualHFSM into a JdeRobot-ROS component to do the same with a different visual language, Scratch. The goal is to explore the use of Scratch with robots, both simulated or real, that JdeRobot-ROS allows and simplifies. We will start with simulated robots in Gazebo, despite with real robots will be the same as they use the same interfaces.

<img src="/assets/images/activities/gsoc/scratch.jpg"> 

<br/>


**Expected results:** new tool prototype that reads Scratch programs and translate them into ROS Python components. 

**Knowledge Prerequisite:** Python programming skills, ROS robotic middleware 

**Mentors:** [Jose María Cañas](http://gsyc.es/jmplaza) (jmplaza AT gsyc.es), L.Roberto Morales (lr.morales.iglesias AT gmail.com) 


## Project #6: Improved video support and transmission in JdeRobot

**Brief Explanation**: In JdeRobot we use the Cameraserver component and ROS node for USB cameras to provide images to applications, frame by frame. Currently video files, webcams, v4linux cameras and firewire cameras are supported. Cameraserver uses OpenCV. We would like to extend the supported image sources (GoPro cameras, web videos like YouTube..). In addition we would like to improve the frame rate between image servers and JdeRobot applications, like [Cameraview](http://wiki.jderobot.org/index.php/Tools#CameraView) or [cameraviewJS](http://wiki.jderobot.org/Aitormf-tfg#CameraViewJS) from a web browser. Currently image transmission can be with or without compression. The compressed software needs to be improved.

<img src="/assets/images/activities/gsoc/cameraview.png"> 

<img src="/assets/images/activities/gsoc/cameraviewjs.png"> 

<br/>


**Expected results:** improved cameraserver component 

**Knowledge Prerequisite:** C++, Python and JavaScript programming skills

**Mentors:** Aitor Martínez (aitor.martinez.fernandez AT gmail..es) 


## Project #7: 3D Self localization (visualSLAM) component with RGBD sensor

**Brief Explanation**: RBGD sensors such as Kinect1 and Kinect2 from Microsoft, Xtion Pro Live from Asus and Astra from Orbbec are very useful in robotics as cheap 3D sensors, for obstacle detection, for map building, self localization, robot navigation, etc. Several visualSLAM techniques are available in the scientific community to solve the 3D Self Localization of a RGBD sensor in real time with no a priori environment map. We are interested in robustly solving the 3D localization problem of a moving RGBD sensor in real time. Knowing reliably the (3D) position opens the door to robust autonomous indoor navigation of drones, for instance. 

<img src="/assets/images/activities/gsoc/rgbdslam.png"> 

<br/>


**Expected results:** a JdeRobot component which provides a 3D pose estimation (position and orientation) in real time using the pose3D ICE interface 

**Knowledge Prerequisite:** C++ programming skills

**Mentors:** Francisco Rivas (franciscomiguel.rivas AT urjc.es), Alberto Martín (almartinflorido AT gmail.com) 


## Project #8: Deep Learning to detect objects at images from RGBD sensors

**Brief Explanation**: Deep learning is a fast-growing field between computer vision researchers. There are several challenges such as COCO and Pascal VOC based on the application of this techniques to detect objects directly over the images. The main idea of this project is to apply this techniques by fusing rgb and depth sensor (data acquired from xtion sensors) to improve the object detection based only on rgb data.

<img src="/assets/images/activities/gsoc/cnn-depth.png" style="height:500px;"> 

<br/>

**Expected results:** A cnn network configuration to combine depth and rgb data to detect objects 

**Knowledge Prerequisite:** C++ programming skills, computer vision, object detection, classifications, deep learning, tensor flow 

**Mentors:** Francisco Rivas (franciscomiguel.rivas AT urjc.es) 

<br/>


# Application instructions for GSoC-2017

We welcome students to contact relevant mentors before submitting their application into GSoC official website. If in doubt for which project(s) to contact, send the mail to jmplaza AT gsyc.es and to franciscomiguel.rivas AT urjc.es, and almartinflorido AT gmail.com We recommend browsing previous GSoC student pages to look for ready-to-use projects, and to get an idea of the expected amount of work for a valid GSoC proposal. 

## Requirements

* Git experience

* C++ and Python programming experience (depending on the project)

## Programming tests

|    **Project**   |     [#1](https://jderobot.github.io/activities/gsoc/2017#project-1-teachingrobotics-a-formula-1-race-in-gazebo-7)     |      [#2](https://jderobot.github.io/activities/gsoc/2017#project-2-teachingrobotics-localization-exercise-from-a-given-map)      |     [#3](https://jderobot.github.io/activities/gsoc/2017#project-3-reinforcement-learning-in-jderobot-openai-gym-and-gazebo)     |     [#4](https://jderobot.github.io/activities/gsoc/2017#project-4-automatic-generation-of-ros-node-with-an-automaton-using-visualhfsm-tool)     |     [#5](https://jderobot.github.io/activities/gsoc/2017#project-5-translation-of-a-scratch-program-to-ros-python-component)     |     [#6](https://jderobot.github.io/activities/gsoc/2017#project-6-improved-video-support-and-transmission-in-jderobot)     |     [#7](https://jderobot.github.io/activities/gsoc/2017#project-7-3d-self-localization-visualslam-component-with-rgbd-sensor)     |     [#8](https://jderobot.github.io/activities/gsoc/2017#project-8-deep-learning-to-detect-objects-at-images-from-rgbd-sensors)     |
| **JdeRobot (A)** |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |
|    **C++ (B)**   |     *     |     *     |     *     |     X     |     *     |     X     |     X     |     O     |
|  **Python (C)**  |     X     |     X     |     X     |     X     |     X     |     X     |     *     |     O     |



<br/>


|                **Legend**                ||
| * |             Not applicable            |
| X |                Mandatory              |
| O | Optative, you must choose one of them |


Before accepting any proposal all candidates have to do these programming challenges: 

* (A) [JdeRobot installation challenge](http://wiki.jderobot.org/store/jmplaza/uploads/gsoc/programming-test-compiling.pdf JdeRobot)

* (B) [C++ challenge](http://wiki.jderobot.org/store/jmplaza/uploads/gsoc/programming-test-c.pdf)

* (C) [Python challenge](http://wiki.jderobot.org/store/jmplaza/uploads/gsoc/programming-test-python.pdf)


## Send us your information

After doing the programming tests, fill this [web form](https://docs.google.com/forms/d/e/1FAIpQLSdq-vhedyOPL1DUk4ZLa8L4uUGnwKV3y2C9D05azFufn79vbQ/viewform) with your information and challenge results. Then you are invited to ask the project mentors about the project details. Maybe we will require more information from you like this: 

1. Contact details

* Name and surname: 

* Country: 

* Email: 

* Public repository/ies: 

* Personal blog (optional): 

* Twitter/Identica/LinkedIn/others: 


2. Timeline

* Now split your project idea in smaller tasks. Quantify the time you think each task needs. Finally, draw a tentative project plan (timeline) including the dates covering all period of GSoC. Don’t forget to include also the days in which you don’t plan to code, because of exams, holidays etc. 

* Do you understand this is a serious commitment, equivalent to a full-time paid summer internship or summer job? 

* Do you have any known time conflicts during the official coding period? 


3. Studies

* What is your School and degree? 

* Would your application contribute to your ongoing studies/degree? If so, how?


4. Programming background

* Computing experience: operating systems you use on a daily basis, known programming languages, hardware, etc.

* Robot or Computer Vision programming experience:

* Other software programming:


5. GSoC participation

* Have you participated to GSoC before? 

* How many times, which year, which project?

* Have you applied but were not selected? When?

* Have you submitted/will you submit another proposal for GSoC 2017 to a different org?


# Previous GSoC students

* [Lihang Li](https://wiki.jderobot.org/Hustcalm-colab) (GSoC-2015) Visual SLAM, RGBD, 3D Reconstruction

* [Andrei Militaru](https://wiki.jderobot.org/Militaru92-colab) (GSoC-2015) interoperation of ROS and JdeRobot

* [Satyaki Chakraborty](https://wiki.jderobot.org/Chakraborty-colab) (GSoC-2015) Interconnection with Android Wear


# How to increase your chances of being selected in GSoC-2017

If you put yourself in the shoes of the mentor that should select the student, you'll immediately realize that there are some behaviors that are usually rewarded. Here's some examples. 

1. Be proactive

Mentors are more likely to select students that openly discuss the existing ideas and / or propose their own. It is a **bad idea** to just submit your idea only in the Google web site without discussing it, because it won't be noticed. 

2. Demonstrate your skills

Consider that mentors are being contacted by several students that apply for the same project. A way to show that you are the best candidate, is to demonstrate that you are familiar with the software and you can code. How? Browse the bug tracker (issues in github of JdeRobot project), fix some bugs and propose your patch in mailing list, and/or ask mentors to challenge you! Moreover, bug fixes are a great way to get familiar with the code. 

3. Demonstrate your intention to stay

Students that are likely to disappear after GSoC are less likely to be selected. This is because there is no point in developing something that won't be maintained. And moreover, one scope of GSoC is to bring new developers to the community. 

# [RTFM](https://xkcd.com/293/)

Read the relevant information about GSoC in the wiki / web pages before asking. Most FAQs have been answered already! 

* [Full documentation about GSoC on official website.](https://developers.google.com/open-source/gsoc/resources/)

* [FAQ from GSoC web site](https://developers.google.com/open-source/gsoc/faq).

* If you are new to JdeRobot, take the time to familiarize with the [JdeRobot](https://jderobot.org)



